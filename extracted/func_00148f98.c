void func_00148f98() {
    // MIPS register variables
    int32_t v0, v1, a0, a1, a2, a3, t0, t1, t2, t3, t4, t5, t6, t7, t8, t9;
    int32_t s0, s1, s2, s3, s4, s5, s6, s7;
    uintptr_t sp, gp, fp, ra;                                   // Pointer registers (as integers for arithmetic)
    int32_t at;                                                 // Assembler temporary register
    int32_t hi, lo;                                             // Multiply/divide result registers
    
    v1 = *(int32_t*)((t1) + 0x10);                              // 0x00148fa0: lw $v1, 0x10($t1)
    a1 = *(int32_t*)((t1) + 0x14);                              // 0x00148fa4: lw $a1, 0x14($t1)
    v0 = (v1 < 0) ? 1 : 0;                                      // 0x00148fa8: slti $v0, $v1, 0
    a2 = v1 + 0xf;                                              // 0x00148fac: addiu $a2, $v1, 0xf
    if (v0 != 0) v1 = a2;                                       // 0x00148fb0: movn $v1, $a2, $v0
    v0 = (a1 < 0) ? 1 : 0;                                      // 0x00148fb4: slti $v0, $a1, 0
    a3 = a1 + 0xf;                                              // 0x00148fb8: addiu $a3, $a1, 0xf
    v1 = v1 >> 4;                                               // 0x00148fbc: sra $v1, $v1, 4
    if (v0 != 0) a1 = a3;                                       // 0x00148fc0: movn $a1, $a3, $v0
    a3 = *(int32_t*)(a0);                                       // 0x00148fc4: lw $a3, 0($a0)
    a1 = a1 >> 4;                                               // 0x00148fc8: sra $a1, $a1, 4
    if (v1 <= 0) goto label_0x14a504;                           // 0x00148fcc: blez $v1, 0x14a504
    t3 = *(int32_t*)((t1) + 4);                                 // 0x00148fd0: lw $t3, 4($t1)
    t5 = a1 << 0xa;                                             // 0x00148fd8: sll $t5, $a1, 0xa
    /* nop */                                                   // 0x00148fdc: nop 
label_0x148fe0:
    if (a1 <= 0) goto label_0x14a4f8;                           // 0x00148fe4: blez $a1, 0x14a4f8
    a3 = a3 + t5;                                               // 0x00148fe8: addu $a3, $a3, $t5
label_0x148ff0:
    v0 = *(uint8_t*)(a3);                                       // 0x00148ff0: lbu $v0, 0($a3)
    t2 = t2 + -1;                                               // 0x00148ff4: addiu $t2, $t2, -1
    v0 = v0 << 2;                                               // 0x00148ff8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00148ffc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149000: lw $v1, 0($v0)
    *(uint32_t*)(a2) = v1;                                      // 0x00149004: sw $v1, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149008: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x0014900c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149010: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149014: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149018: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x0014901c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149020: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149024: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149028: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014902c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149030: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149034: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149038: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014903c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149040: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149044: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149048: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014904c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149050: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149054: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149058: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014905c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149060: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149064: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149068: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014906c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149070: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149074: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149078: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014907c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149080: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149084: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149088: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014908c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149090: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149094: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149098: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014909c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001490a0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x001490a4: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x001490a8: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x001490ac: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001490b0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001490b4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x001490b8: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x001490bc: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x001490c0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001490c4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001490c8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x001490cc: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x001490d0: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x001490d4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001490d8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001490dc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x001490e0: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x001490e4: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x001490e8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001490ec: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001490f0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x001490f4: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x001490f8: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x001490fc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149100: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149104: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149108: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x0014910c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149110: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149114: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149118: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x0014911c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149120: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149124: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149128: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014912c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149130: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149134: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149138: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x0014913c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149140: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149144: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149148: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x0014914c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149150: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149154: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149158: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x0014915c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149160: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149164: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149168: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x0014916c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149170: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149174: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149178: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014917c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149180: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149184: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149188: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014918c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149190: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149194: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149198: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014919c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001491a0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x001491a4: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x001491a8: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x001491ac: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001491b0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001491b4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x001491b8: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x001491bc: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x001491c0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001491c4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001491c8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x001491cc: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x001491d0: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x001491d4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001491d8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001491dc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x001491e0: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x001491e4: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x001491e8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001491ec: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001491f0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x001491f4: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x001491f8: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x001491fc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149200: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149204: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x00149208: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x0014920c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x00149210: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149214: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149218: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x0014921c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149220: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149224: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149228: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014922c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149230: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149234: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149238: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014923c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149240: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149244: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149248: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x0014924c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149250: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149254: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149258: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x0014925c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149260: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149264: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149268: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x0014926c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149270: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149274: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149278: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014927c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149280: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149284: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149288: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x0014928c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149290: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149294: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149298: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x0014929c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x001492a0: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x001492a4: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x001492a8: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x001492ac: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001492b0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001492b4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x001492b8: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x001492bc: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x001492c0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001492c4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001492c8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x001492cc: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x001492d0: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x001492d4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001492d8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001492dc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x001492e0: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x001492e4: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x001492e8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001492ec: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001492f0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x001492f4: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x001492f8: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x001492fc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149300: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149304: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149308: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014930c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149310: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149314: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149318: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014931c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149320: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149324: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149328: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014932c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149330: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149334: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149338: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014933c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149340: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x00149344: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x00149348: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x0014934c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149350: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149354: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x00149358: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x0014935c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x00149360: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149364: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149368: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x0014936c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149370: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149374: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149378: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014937c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149380: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149384: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149388: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014938c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149390: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149394: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149398: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x0014939c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001493a0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001493a4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x001493a8: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x001493ac: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x001493b0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001493b4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001493b8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x001493bc: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x001493c0: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x001493c4: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x001493c8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001493cc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001493d0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x001493d4: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x001493d8: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x001493dc: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x001493e0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001493e4: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x001493e8: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x001493ec: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x001493f0: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x001493f4: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x001493f8: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x001493fc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149400: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149404: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149408: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x0014940c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149410: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149414: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149418: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014941c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149420: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149424: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149428: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014942c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149430: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149434: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149438: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014943c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149440: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149444: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149448: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014944c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149450: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149454: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149458: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014945c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149460: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149464: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149468: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014946c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149470: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149474: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149478: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014947c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149480: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149484: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149488: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014948c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149490: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x00149494: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x00149498: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x0014949c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001494a0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001494a4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x001494a8: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x001494ac: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x001494b0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001494b4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001494b8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x001494bc: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x001494c0: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x001494c4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001494c8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001494cc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x001494d0: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x001494d4: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x001494d8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001494dc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001494e0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x001494e4: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x001494e8: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x001494ec: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001494f0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001494f4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x001494f8: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x001494fc: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149500: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149504: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149508: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x0014950c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149510: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149514: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149518: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014951c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149520: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149524: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149528: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x0014952c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149530: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149534: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149538: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x0014953c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149540: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149544: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149548: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x0014954c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149550: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149554: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149558: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x0014955c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149560: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149564: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149568: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014956c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149570: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149574: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149578: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014957c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149580: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149584: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149588: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014958c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149590: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149594: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149598: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014959c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001495a0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001495a4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x001495a8: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x001495ac: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x001495b0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001495b4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001495b8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x001495bc: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x001495c0: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x001495c4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001495c8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001495cc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x001495d0: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x001495d4: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x001495d8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001495dc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001495e0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x001495e4: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x001495e8: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x001495ec: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001495f0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001495f4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x001495f8: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x001495fc: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x00149600: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149604: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149608: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x0014960c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149610: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149614: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149618: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014961c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149620: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149624: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149628: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014962c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149630: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149634: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149638: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x0014963c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149640: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149644: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149648: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x0014964c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149650: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149654: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149658: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x0014965c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149660: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149664: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149668: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014966c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149670: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149674: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149678: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x0014967c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149680: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149684: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149688: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x0014968c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149690: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149694: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149698: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x0014969c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001496a0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001496a4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x001496a8: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x001496ac: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x001496b0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001496b4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001496b8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x001496bc: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x001496c0: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x001496c4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001496c8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001496cc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x001496d0: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x001496d4: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x001496d8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001496dc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001496e0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x001496e4: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x001496e8: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x001496ec: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001496f0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001496f4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x001496f8: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x001496fc: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149700: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149704: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149708: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014970c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149710: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149714: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149718: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014971c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149720: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149724: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149728: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014972c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149730: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x00149734: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x00149738: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x0014973c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149740: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149744: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x00149748: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x0014974c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x00149750: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149754: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149758: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x0014975c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149760: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149764: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149768: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014976c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149770: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149774: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149778: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014977c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149780: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149784: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149788: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x0014978c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149790: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149794: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149798: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x0014979c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x001497a0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001497a4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001497a8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x001497ac: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x001497b0: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x001497b4: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x001497b8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001497bc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001497c0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x001497c4: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x001497c8: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x001497cc: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x001497d0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001497d4: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x001497d8: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x001497dc: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x001497e0: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x001497e4: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x001497e8: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x001497ec: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001497f0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001497f4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x001497f8: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x001497fc: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149800: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149804: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149808: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014980c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149810: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149814: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149818: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014981c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149820: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149824: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149828: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014982c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149830: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149834: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149838: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014983c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149840: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149844: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149848: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014984c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149850: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149854: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149858: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014985c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149860: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149864: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149868: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014986c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149870: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149874: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149878: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014987c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149880: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x00149884: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x00149888: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x0014988c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149890: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149894: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x00149898: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x0014989c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x001498a0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001498a4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001498a8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x001498ac: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x001498b0: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x001498b4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001498b8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001498bc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x001498c0: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x001498c4: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x001498c8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001498cc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001498d0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x001498d4: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x001498d8: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x001498dc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001498e0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001498e4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x001498e8: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x001498ec: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x001498f0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001498f4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001498f8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x001498fc: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149900: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149904: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149908: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014990c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149910: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149914: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149918: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x0014991c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149920: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149924: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149928: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x0014992c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149930: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149934: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149938: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x0014993c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149940: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149944: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149948: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x0014994c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149950: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149954: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149958: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014995c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149960: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149964: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149968: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014996c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149970: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149974: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149978: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014997c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149980: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149984: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149988: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014998c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149990: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149994: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149998: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014999c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x001499a0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001499a4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001499a8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x001499ac: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x001499b0: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x001499b4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001499b8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001499bc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x001499c0: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x001499c4: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x001499c8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001499cc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001499d0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x001499d4: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x001499d8: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x001499dc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001499e0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001499e4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x001499e8: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x001499ec: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x001499f0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x001499f4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x001499f8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x001499fc: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149a00: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149a04: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149a08: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149a0c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149a10: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149a14: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149a18: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149a1c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149a20: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149a24: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149a28: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x00149a2c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149a30: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149a34: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149a38: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x00149a3c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149a40: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149a44: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149a48: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x00149a4c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149a50: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149a54: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149a58: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149a5c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149a60: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149a64: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149a68: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x00149a6c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149a70: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149a74: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149a78: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x00149a7c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149a80: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149a84: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149a88: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x00149a8c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149a90: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149a94: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149a98: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x00149a9c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149aa0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149aa4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149aa8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x00149aac: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149ab0: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149ab4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ab8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149abc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149ac0: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149ac4: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149ac8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149acc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149ad0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149ad4: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149ad8: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x00149adc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ae0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149ae4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149ae8: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x00149aec: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149af0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149af4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149af8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x00149afc: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149b00: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149b04: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149b08: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149b0c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149b10: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149b14: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149b18: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149b1c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149b20: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x00149b24: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x00149b28: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x00149b2c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149b30: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149b34: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x00149b38: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x00149b3c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x00149b40: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149b44: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149b48: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x00149b4c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149b50: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149b54: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149b58: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149b5c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149b60: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149b64: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149b68: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149b6c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149b70: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149b74: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149b78: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x00149b7c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149b80: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149b84: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149b88: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x00149b8c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149b90: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149b94: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149b98: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x00149b9c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149ba0: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149ba4: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149ba8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149bac: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149bb0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149bb4: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149bb8: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x00149bbc: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149bc0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149bc4: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149bc8: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x00149bcc: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149bd0: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149bd4: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149bd8: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x00149bdc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149be0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149be4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149be8: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x00149bec: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149bf0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149bf4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149bf8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x00149bfc: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149c00: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149c04: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149c08: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149c0c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149c10: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149c14: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149c18: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149c1c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149c20: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149c24: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149c28: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x00149c2c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149c30: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149c34: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149c38: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x00149c3c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149c40: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149c44: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149c48: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x00149c4c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149c50: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149c54: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149c58: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149c5c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149c60: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149c64: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149c68: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149c6c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149c70: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x00149c74: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x00149c78: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x00149c7c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149c80: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149c84: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x00149c88: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x00149c8c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x00149c90: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149c94: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149c98: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x00149c9c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149ca0: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149ca4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ca8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149cac: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149cb0: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149cb4: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149cb8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149cbc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149cc0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149cc4: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149cc8: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x00149ccc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149cd0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149cd4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149cd8: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x00149cdc: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149ce0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ce4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149ce8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x00149cec: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149cf0: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149cf4: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149cf8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149cfc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149d00: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149d04: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149d08: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x00149d0c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149d10: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149d14: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149d18: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x00149d1c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149d20: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149d24: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149d28: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x00149d2c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149d30: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149d34: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149d38: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x00149d3c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149d40: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149d44: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149d48: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x00149d4c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149d50: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149d54: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149d58: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149d5c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149d60: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149d64: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149d68: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149d6c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149d70: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149d74: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149d78: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x00149d7c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149d80: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149d84: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149d88: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x00149d8c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149d90: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149d94: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149d98: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x00149d9c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149da0: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149da4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149da8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149dac: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149db0: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149db4: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149db8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149dbc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149dc0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x00149dc4: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x00149dc8: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x00149dcc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149dd0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149dd4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x00149dd8: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x00149ddc: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x00149de0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149de4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149de8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x00149dec: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149df0: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149df4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149df8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149dfc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149e00: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149e04: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149e08: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149e0c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149e10: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149e14: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149e18: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x00149e1c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149e20: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149e24: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149e28: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x00149e2c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149e30: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149e34: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149e38: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x00149e3c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149e40: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149e44: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149e48: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149e4c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149e50: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149e54: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149e58: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x00149e5c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149e60: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149e64: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149e68: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x00149e6c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149e70: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149e74: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149e78: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x00149e7c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149e80: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149e84: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149e88: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x00149e8c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149e90: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149e94: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149e98: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x00149e9c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149ea0: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149ea4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ea8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149eac: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x00149eb0: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x00149eb4: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x00149eb8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ebc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149ec0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x00149ec4: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x00149ec8: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x00149ecc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ed0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149ed4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x00149ed8: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x00149edc: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x00149ee0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ee4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149ee8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x00149eec: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x00149ef0: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x00149ef4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ef8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149efc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x00149f00: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x00149f04: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x00149f08: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149f0c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149f10: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x00149f14: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x00149f18: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x00149f1c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149f20: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149f24: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x00149f28: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x00149f2c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x00149f30: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149f34: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149f38: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x00149f3c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x00149f40: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x00149f44: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149f48: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149f4c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x00149f50: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x00149f54: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x00149f58: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149f5c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149f60: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x00149f64: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x00149f68: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x00149f6c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149f70: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149f74: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x00149f78: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x00149f7c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x00149f80: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149f84: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149f88: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x00149f8c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x00149f90: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x00149f94: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x00149f98: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149f9c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149fa0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x00149fa4: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x00149fa8: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x00149fac: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x00149fb0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149fb4: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x00149fb8: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x00149fbc: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x00149fc0: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x00149fc4: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x00149fc8: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x00149fcc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149fd0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149fd4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x00149fd8: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x00149fdc: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x00149fe0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149fe4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149fe8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x00149fec: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x00149ff0: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x00149ff4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x00149ff8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x00149ffc: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x0014a000: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x0014a004: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x0014a008: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a00c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a010: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x0014a014: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x0014a018: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014a01c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a020: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a024: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x0014a028: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014a02c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x0014a030: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a034: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a038: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014a03c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x0014a040: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x0014a044: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a048: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a04c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x0014a050: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x0014a054: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x0014a058: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a05c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a060: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x0014a064: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x0014a068: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x0014a06c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a070: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a074: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x0014a078: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x0014a07c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x0014a080: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a084: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a088: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x0014a08c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x0014a090: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x0014a094: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a098: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a09c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x0014a0a0: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x0014a0a4: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x0014a0a8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a0ac: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a0b0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x0014a0b4: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x0014a0b8: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x0014a0bc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a0c0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a0c4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x0014a0c8: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x0014a0cc: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x0014a0d0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a0d4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a0d8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x0014a0dc: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x0014a0e0: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x0014a0e4: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x0014a0e8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a0ec: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a0f0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x0014a0f4: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x0014a0f8: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x0014a0fc: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x0014a100: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a104: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x0014a108: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x0014a10c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x0014a110: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x0014a114: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x0014a118: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x0014a11c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a120: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a124: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x0014a128: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x0014a12c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x0014a130: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a134: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a138: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014a13c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x0014a140: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x0014a144: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a148: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a14c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x0014a150: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x0014a154: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x0014a158: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a15c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a160: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x0014a164: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x0014a168: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014a16c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a170: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a174: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x0014a178: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014a17c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x0014a180: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a184: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a188: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014a18c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x0014a190: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x0014a194: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a198: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a19c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x0014a1a0: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x0014a1a4: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x0014a1a8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a1ac: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a1b0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x0014a1b4: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x0014a1b8: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x0014a1bc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a1c0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a1c4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x0014a1c8: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x0014a1cc: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x0014a1d0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a1d4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a1d8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x0014a1dc: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x0014a1e0: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x0014a1e4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a1e8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a1ec: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x0014a1f0: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x0014a1f4: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x0014a1f8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a1fc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a200: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x0014a204: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x0014a208: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x0014a20c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a210: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a214: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x0014a218: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x0014a21c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x0014a220: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a224: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a228: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x0014a22c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x0014a230: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x0014a234: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x0014a238: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a23c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a240: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x0014a244: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x0014a248: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x0014a24c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x0014a250: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a254: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x0014a258: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x0014a25c: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x0014a260: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x0014a264: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x0014a268: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x0014a26c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a270: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a274: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x0014a278: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x0014a27c: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x0014a280: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a284: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a288: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014a28c: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x0014a290: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x0014a294: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a298: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a29c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x0014a2a0: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x0014a2a4: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x0014a2a8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a2ac: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a2b0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x0014a2b4: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x0014a2b8: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014a2bc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a2c0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a2c4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x0014a2c8: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014a2cc: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x0014a2d0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a2d4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a2d8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014a2dc: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x0014a2e0: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x0014a2e4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a2e8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a2ec: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x0014a2f0: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x0014a2f4: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x0014a2f8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a2fc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a300: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x0014a304: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x0014a308: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x0014a30c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a310: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a314: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x0014a318: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x0014a31c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x0014a320: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a324: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a328: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x0014a32c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x0014a330: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x0014a334: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a338: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a33c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x0014a340: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x0014a344: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x0014a348: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a34c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a350: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x0014a354: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x0014a358: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x0014a35c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a360: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a364: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x0014a368: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x0014a36c: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x0014a370: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a374: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a378: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x0014a37c: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x0014a380: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x0014a384: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x0014a388: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a38c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a390: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x0014a394: sw $v1, 0x3c($a2)
    v0 = *(uint8_t*)(a3);                                       // 0x0014a398: lbu $v0, 0($a3)
    v1 = *(int32_t*)((t1) + 8);                                 // 0x0014a39c: lw $v1, 8($t1)
    v0 = v0 << 2;                                               // 0x0014a3a0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a3a4: addu $v0, $v0, $t0
    v1 = v1 << 2;                                               // 0x0014a3a8: sll $v1, $v1, 2
    a0 = *(int32_t*)(v0);                                       // 0x0014a3ac: lw $a0, 0($v0)
    a2 = a2 + v1;                                               // 0x0014a3b0: addu $a2, $a2, $v1
    *(uint32_t*)(a2) = a0;                                      // 0x0014a3b4: sw $a0, 0($a2)
    v0 = *(uint8_t*)((a3) + 4);                                 // 0x0014a3b8: lbu $v0, 4($a3)
    v0 = v0 << 2;                                               // 0x0014a3bc: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a3c0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a3c4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 4) = v1;                                // 0x0014a3c8: sw $v1, 4($a2)
    v0 = *(uint8_t*)((a3) + 8);                                 // 0x0014a3cc: lbu $v0, 8($a3)
    v0 = v0 << 2;                                               // 0x0014a3d0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a3d4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a3d8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 8) = v1;                                // 0x0014a3dc: sw $v1, 8($a2)
    v0 = *(uint8_t*)((a3) + 0xc);                               // 0x0014a3e0: lbu $v0, 0xc($a3)
    v0 = v0 << 2;                                               // 0x0014a3e4: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a3e8: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a3ec: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0xc) = v1;                              // 0x0014a3f0: sw $v1, 0xc($a2)
    v0 = *(uint8_t*)((a3) + 0x10);                              // 0x0014a3f4: lbu $v0, 0x10($a3)
    v0 = v0 << 2;                                               // 0x0014a3f8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a3fc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a400: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x10) = v1;                             // 0x0014a404: sw $v1, 0x10($a2)
    v0 = *(uint8_t*)((a3) + 0x14);                              // 0x0014a408: lbu $v0, 0x14($a3)
    v0 = v0 << 2;                                               // 0x0014a40c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a410: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a414: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x14) = v1;                             // 0x0014a418: sw $v1, 0x14($a2)
    v0 = *(uint8_t*)((a3) + 0x18);                              // 0x0014a41c: lbu $v0, 0x18($a3)
    v0 = v0 << 2;                                               // 0x0014a420: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a424: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a428: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x18) = v1;                             // 0x0014a42c: sw $v1, 0x18($a2)
    v0 = *(uint8_t*)((a3) + 0x1c);                              // 0x0014a430: lbu $v0, 0x1c($a3)
    v0 = v0 << 2;                                               // 0x0014a434: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a438: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a43c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x1c) = v1;                             // 0x0014a440: sw $v1, 0x1c($a2)
    v0 = *(uint8_t*)((a3) + 0x20);                              // 0x0014a444: lbu $v0, 0x20($a3)
    v0 = v0 << 2;                                               // 0x0014a448: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a44c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a450: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x20) = v1;                             // 0x0014a454: sw $v1, 0x20($a2)
    v0 = *(uint8_t*)((a3) + 0x24);                              // 0x0014a458: lbu $v0, 0x24($a3)
    v0 = v0 << 2;                                               // 0x0014a45c: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a460: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a464: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x24) = v1;                             // 0x0014a468: sw $v1, 0x24($a2)
    v0 = *(uint8_t*)((a3) + 0x28);                              // 0x0014a46c: lbu $v0, 0x28($a3)
    v0 = v0 << 2;                                               // 0x0014a470: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a474: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a478: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x28) = v1;                             // 0x0014a47c: sw $v1, 0x28($a2)
    v0 = *(uint8_t*)((a3) + 0x2c);                              // 0x0014a480: lbu $v0, 0x2c($a3)
    v0 = v0 << 2;                                               // 0x0014a484: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a488: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a48c: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x2c) = v1;                             // 0x0014a490: sw $v1, 0x2c($a2)
    v0 = *(uint8_t*)((a3) + 0x30);                              // 0x0014a494: lbu $v0, 0x30($a3)
    v0 = v0 << 2;                                               // 0x0014a498: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a49c: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a4a0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x30) = v1;                             // 0x0014a4a4: sw $v1, 0x30($a2)
    v0 = *(uint8_t*)((a3) + 0x34);                              // 0x0014a4a8: lbu $v0, 0x34($a3)
    v0 = v0 << 2;                                               // 0x0014a4ac: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a4b0: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a4b4: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x34) = v1;                             // 0x0014a4b8: sw $v1, 0x34($a2)
    v0 = *(uint8_t*)((a3) + 0x38);                              // 0x0014a4bc: lbu $v0, 0x38($a3)
    v0 = v0 << 2;                                               // 0x0014a4c0: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a4c4: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a4c8: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x38) = v1;                             // 0x0014a4cc: sw $v1, 0x38($a2)
    v0 = *(uint8_t*)((a3) + 0x3c);                              // 0x0014a4d0: lbu $v0, 0x3c($a3)
    a3 = a3 + 0x40;                                             // 0x0014a4d4: addiu $a3, $a3, 0x40
    v0 = v0 << 2;                                               // 0x0014a4d8: sll $v0, $v0, 2
    v0 = v0 + t0;                                               // 0x0014a4dc: addu $v0, $v0, $t0
    v1 = *(int32_t*)(v0);                                       // 0x0014a4e0: lw $v1, 0($v0)
    *(uint32_t*)((a2) + 0x3c) = v1;                             // 0x0014a4e4: sw $v1, 0x3c($a2)
    v0 = *(int32_t*)((t1) + 8);                                 // 0x0014a4e8: lw $v0, 8($t1)
    v0 = v0 << 2;                                               // 0x0014a4ec: sll $v0, $v0, 2
    if (t2 != 0) goto label_0x148ff0;                           // 0x0014a4f0: bnez $t2, 0x148ff0
    a2 = a2 + v0;                                               // 0x0014a4f4: addu $a2, $a2, $v0
label_0x14a4f8:
    t4 = t4 + -1;                                               // 0x0014a4f8: addiu $t4, $t4, -1
    if (t4 != 0) goto label_0x148fe0;                           // 0x0014a4fc: bnez $t4, 0x148fe0
    t3 = t3 + 0x40;                                             // 0x0014a500: addiu $t3, $t3, 0x40
label_0x14a504:
    return;                                                     // 0x0014a504: jr $ra
    /* nop */                                                   // 0x0014a508: nop 
}